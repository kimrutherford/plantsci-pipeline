# -*- org -*-
###+INFOJS_OPT: view:content toc:t ltoc:t mouse:#dddddd
#+OPTIONS:     H:5

University of Cambridge Department of Plant Sciences NGS processing pipeline

* Introduction
  - a relatively generic pipeline for processing NGS data
  - handles
    - sRNA
    - SAGE
    - mRNA expression (non-SAGE)
  - Features
    - Handles dependencies between jobs
    - Results are stored in a database
* Requirements
** Linux (or UNIX)
** Perl
** Perl libraries
   If all goes well these will be installed by the installer as needed
** PostgreSQL and its development libraries
   The pipeline was developed using [[http://www.postgresql.org/][PostgreSQL]] 8.3, but any recent version
   should work.
* Getting the code
  Currently the easiest way to get the code is via Github:
#+BEGIN_SRC sh
  git clone git://github.com/kimrutherford/plantsci-pipeline.git pipeline
#+END_SRC
* Installation
** PostgreSQL libraries
   The [[http://www.postgresql.org/][PostgreSQL]] server and development libraries need to be installed first.

   On a Debian system the command is:
#+BEGIN_SRC sh
  apt-get install postgresql-8.3 postgresql-server-dev-8.3
#+END_SRC

** Perl code
Install with the usual Perl installation commands.  This may need to be done
as root.  The "make install" step will install any necessary Perl package
dependencies.
#+BEGIN_SRC sh
  cd pipeline
  perl Makefile.PL
  make install
#+END_SRC

** Database initialisation
#+BEGIN_SRC sh
  createdb pipeline
  psql pipeline < etc/schema.sql
#+END_SRC
* Configuration
** The configuration file
   The configuration file for is created by the =pipeinit.pl= script and
   containing global configuration.  Other configuration is [[Configuration in the database][stored in the database]].
#+BEGIN_SRC sh
  ./script/pipeinit.pl -f etc/example_deploy_params
#+END_SRC
  This will create a file named =pipeline-example-config.yaml=.
*** Configuration options
**** =pipeline_directory=
     This is the root directory for pipeline operation.  It needs to be
     writable by the user that will run the [[The pipeline server][pipeline server]].
**** =data_sub_directory=
     This a the sub directory of =pipeline_directory= where pipeline results
     will be stored.
**** "Model::SmallRNAModel"
     This section configures the connection from =DBIx::Class= to the
     database.  These options need to be set:
  - =dbname= - the database name
  - =host=
  - 'some_user'
  - 'user_password'
**** =programs=
     Each external program needs a =path= setting - the path to the executable
     for this program.

     A program that is run from the [[SmallRNA::Runable::AlignmentRunable][AlignmentRunable]] will need a
     =process_class= setting to specify the class to use to run the program.
**** =databases=
     This section configures the sequence databases used in the pipeline,
     mainly by the alignment programs.
***** =root=
      All paths in this section are relative to the =root=, which can be =/=
***** =organisms= / =database_files=
      There may be multiple database files for each organism.  Each file has a
      tag like =genome= or =mrna=.  These tags are referred to as "components"
      in other parts of the code.
** Configuration in the database
   Settings that may need to be configured after the pipeline is running are
   stored in the database.  See the documentation for the following tables:
   [[=barcode=][barcode]], [[=barcode_set=][barcode_set]], [[=cvterm=][cvterm]], [[=ecotype=][ecotype]], [[=organisation=][organisation]], [[=organism=][organism]], [[=person=][person]],
   [[=process_conf=][process_conf]] and [[=process_conf_input=][process_conf_input]]

* Database structure
** Tables
*** =barcode=
    Sequence and short name (code) used for multiplexed sequencing runs.

    Columns of this table:
 - =identifier= :: the user friendly identifier of this barcode
 - =code= :: the barcode
*** =barcode_set=
    A collection of barcodes that are used together.

    Columns of this table:
 - =name= :: The user friendly name for this =barcode_set=
*** =coded_sample=
    This table connects a [[sequencing_sample][sequencing sample]], a [[biosample]] and a [[barcode]].  The bar
    code is optional as a sequencing sample isn't always multiplexed.

    Columns of this table:
 - =coded_sample_type= :: specifies whether this =coded_sample= is an initial
   run or a technical replicate or biological replicate.
 - =description= :: an optional description
*** =cv=
    Controlled vocabulary table copied from the [[http://gmod.org/wiki/Chado][Chado]] [[http://gmod.org/wiki/Chado_CV_Module][CV Module]].
*** =cvterm=
    Controlled vocabulary term table from the [[http://gmod.org/wiki/Chado][Chado]] [[http://gmod.org/wiki/Chado_CV_Module][CV Module]].
*** =cvterm_dbxref=
    A link table connecting references to cvterms.
*** =db=
    Database table from the [[http://gmod.org/wiki/Chado][Chado]] [[http://gmod.org/wiki/Chado_CV_Module][CV Module]].
*** =dbxref=
    [[http://gmod.org/wiki/Chado_General_Module#Table:_dbxref][Database cross reference]] table from the [[http://gmod.org/wiki/Chado][Chado]] [[http://gmod.org/wiki/Chado_General_Module][General Module]].
*** =ecotype=
    An ecotype (also known as a strain or stock) of an [[organism]]

    Columns of this table:
    - =description= :: the common/standard description of the ecotype
*** =organisation=
    Each person is a member of an =organisation= and sequencing centres are
    organisations in this schema.  A =pipeproject= has an optional =funder=
    that is also an =organisation=.
*** =organism=
    Organism table from the [[http://gmod.org/wiki/Chado][Chado]] [[http://gmod.org/wiki/Chado_Organism_Module][Organism Module]].
*** =organism_dbxref=
    Organism to reference link table from the [[http://gmod.org/wiki/Chado][Chado]] [[http://gmod.org/wiki/Chado_Organism_Module][Organism Module]].
*** =person=
    Notable columns of this table:
    - =role= :: the role is used by the tracking application to control
      capabilities.
*** =pipedata=
    The pipeline creates a row in this table for each file that a
    [[Pipeline processes][process]] creates and records the file location (in =file_name=) and its
    size.  This table also tracks the content type and
    format type of the file so that [[Pipeline processes][processes]] can find input files of the
    correct type.

    Columns of this table:
    - =content_type= :: a cvterm specifying the content type.
      eg. "raw_reads", "aligned_reads"
    - =format_type= :: a cvterm recording the format of the file.
      eg. "fasta", "gff3"
    - =file_length= :: the data file length
    - =generating_pipeprocess= :: the id of the [[=pipeprocess=]] that generated
      this =pipedata=
*** =pipedata_property=
    Key/value pairs for a =pipedata= entry.

    Columns of this table:
    - =type= :: the key of the pair
    - =value= :: the value as text
    - =pipedata= :: the =pipedata= for the property
*** =pipeprocess=
    This table records the tasks performed by the pipeline.  Each row
    references the =process_conf= that holds the configuration for this
    process.  Each process is run by the [[The pipeline worker][pipeline worker]] script
    (=pipework.pl=).

    Columns of this table:
    - =description= :: a human readable description of the process.
    - =process_conf= :: the =process_conf= that will be used by this
      pipeprocess.
    - =status= :: this is the status field is used by the [[The pipeline server][pipeline server]] and
      will have values from the cvterm table like: "not_started", "started",
      "queued", "finished" or "failed".  See the [[The pipeline server][pipeline server]] section for
      descriptions of each state.
    - =job_identifier= :: the identifier of this process in the job queueing
      system (currently Torque).
    - =time_queued= :: the time when this process moved to the "queued" state,
      otherwise null.
    - =time_started= :: the time when this process moved to the "started" state,
      otherwise null.
    - =time_finished= :: the time when this process moved to the "finished" state,
      otherwise null.
*** =pipeprocess_in_pipedata=
    This table contains the input files ([[=pipedata=]] entries) for the
    pipeprocesses.

    Columns of this table:
*** =pipeprocess_pub=
    Columns of this table:
*** =pipeproject=
    Columns of this table:
*** =process_conf=
    Columns of this table:
*** =process_conf_input=
    Columns of this table:
*** =protocol=
    Columns of this table:
*** =pub=
*** =pub_dbxref=
*** =biosample=
    Columns of this table:
*** =biosample_dbxref=
    Columns of this table:
*** =biosample_ecotype=
    Columns of this table:
*** =biosample_pipedata=
    Columns of this table:
*** =biosample_pipeproject=
    Columns of this table:
*** =sequencing_sample=
    Columns of this table:
*** =sequencingrun=
    Columns of this table:
*** =tissue=
    Columns of this table:
* Operation
** Pipeline processes
   Each process / job that the pipeline runs will have an entry in the
   [[=pipeprocess=][pipeprocess]] table.
** Pipeline data
** The pipeline server
   The script that controls the pipeline is =pipeserv.pl=.
   - creates new processes (entries in the =pipeprocess= table) using the [[SmallRNA::ProcessManager][ProcessManager]]
   - queues new jobs using torque
   - sleeps, then starts again
*** Process states
    - not_started :: Process has not been queued yet - there is an entry in
      the database, but no Torque/Condor job has been created (set by
      =pipeserv.pl=)
    - queued :: A job is queued to run this process - a Torque/Condor job has
      been created (set by =pipeserv.pl=)
    - started :: Processing has started - Torque/Condor has started running
      this process (set by =pipework.pl=)
    - finished :: Processing is done - the process finished and succeeded (set
      by =pipework.pl=)
    - failed :: Processing failed - the process finished and failed (set by
      =pipework.pl=)
** The pipeline worker
   Each job is run by =pipework.pl=.  It receives the ID of a [[pipeprocess][=pipeprocess=]] and
   the path to the configuration file as environment variables.
* Implementation
** Runables
** SmallRNA::Runable::AlignmentRunable
   - configured using the =process_class= setting in the config file
** SmallRNA::ProcessManager
   - code for creating [[=pipeprocess=]] entries
